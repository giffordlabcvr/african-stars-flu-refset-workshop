## 1.2 (Optional) Command line interface (CLI)-based approach: NCBI Nucleotide

<img src="../images/ncbi.jpg" align="right" alt="" width="110"/>

This optional path shows an end-to-end, reproducible workflow using **NCBI EDirect** + **Dockerised Nextclade** + **Nextstrain/Augur**. It produces a curated HA reference set and an Auspice viewable tree, *without* relying on GISAID-derived metadata.

> **You'll need**:
> - EDirect (for fetching from NCBI)
> - Docker (for Nextclade & Nextstrain tools)
> - A "master" reference sequence (we'll fetch it; you can also use your pre-chosen one)

Alternatively, you can proceed with tutorial by utilising a dataset previously downloaded from **GISAID**, as described **[here](https://github.com/giffordlabcvr/african-stars-flu-refset-workshop/blob/main/tutorial/1.3-get-raw-data-web-gisaid.md)**.  


* * * * *


### 1.2.0. Install EDirect (macOS/Linux/WSL)

Script (official):

```
sh -c "$(curl -fsSL https://ftp.ncbi.nlm.nih.gov/entrez/entrezdirect/install-edirect.sh)"
export PATH="$PATH:$HOME/edirect"
```


* * * * *

### 1.2.1 Fetch **HA-only** sequences (H3N2, South Africa, 2000--2025)

**Why this query?** It limits to influenza A (H3N2), **HA gene** only, South Africa, 2000--2025, with a length guard typical for HA (1,500--1,900 nt).

```
# FASTA (HA only)\
esearch -db nucleotide -query \
'"Alphainfluenzavirus"[Organism] AND H3N2[All Fields] AND (HA[Gene] OR hemagglutinin[Gene]) \
AND "South Africa"[All Fields] AND ("2000/01/01"[PDAT] : "2025/12/31"[PDAT]) \
AND 1500:1900[SLEN]' \
| efetch -format fasta > sa_h3n2_HA_2000_2025.fasta
```
Quick sanity check - Count the number of sequences in the FASTA file

```
grep -c '^>' sa_h3n2_HA_2000_2025.fasta
```

Also grab GenBank flatfiles with /source qualifiers

```
# GBK (HA only) -- for metadata extraction\
esearch -db nucleotide -query \
'"Alphainfluenzavirus"[Organism] AND H3N2[All Fields] AND (HA[Gene] OR hemagglutinin[Gene]) \
AND "South Africa"[All Fields] AND ("2000/01/01"[PDAT] : "2025/12/31"[PDAT]) \
AND 1500:1900[SLEN]' \
| efetch -format gbc > sa_h3n2_HA_2000_2025.gbk
```


* * * * *

### 1.2.2 Nextclade (Docker) --- download dataset & run QC/genotyping

<img src="../images/nextstrain.png" align="right" alt="" width="100"/> 

**What is Nextclade doing here?**

Nextclade compares each sequence to a **curated dataset** (reference, gene coordinates, clade rules, QC thresholds) and returns:

-   **Clade calls** (e.g., Nextstrain H3N2 clades),
-   **QC metrics** (overall pass/warn/fail + reasons),
-   Optional **aligned sequences** (if you ask for them).

We'll use the **H3N2 / HA** dataset so clade/QC logic matches your input.

**Why "dataset get"?**

This **downloads & caches** the pathogen-/gene-specific bundle under `~/.nextclade/...` so runs are fast and reproducible. We mount your host `~/.nextclade` into the container so the cache persists across runs.

**a)** Download the **H3N2 HA** dataset (cached under `~/.nextclade`)

```
# Download H3N2 HA dataset (cached)
docker run --rm -it \
  -v "$HOME/.nextclade":/root/.nextclade \
  nextstrain/nextclade:latest \
  nextclade dataset get \
    --name nextstrain/flu/h3n2/ha \
    --output-dir /root/.nextclade/datasets/h3n2_ha
```

**b)** Run Nextclade

```
# QC + clade calls (TSV)
docker run --rm -it \
  -v "$PWD":/data \
  -v "$HOME/.nextclade":/root/.nextclade \
  nextstrain/nextclade:latest \
  nextclade run \
    --input-dataset /root/.nextclade/datasets/h3n2_ha \
    --output-tsv /data/nextclade.tsv \
    /data/sa_h3n2_HA_2000_2025.fasta
```

✅ **Checkpoint** `nextclade.tsv` should exist.

* * * * *


### 1.2.3 Extract minimal metadata from GBK and join with Nextclade

We'll take **accession**, **collection_date**, **geo_loc_name** from GBK and join to Nextclade results. Nextclade's `seqName` often includes long descriptions; we'll map it to the accession by taking the **first token**.

**a)** Minimal metadata (accession, collection_date, geo_loc_name)

```
xtract -input sa_h3n2_HA_2000_2025.gbk -pattern INSDSeq \
  -element INSDSeq_primary-accession \
  -block INSDQualifier -if INSDQualifier_name -equals collection_date -element INSDQualifier_value \
  -block INSDQualifier -if INSDQualifier_name -equals geo_loc_name     -element INSDQualifier_value \
  > metadata_raw.tsv
# columns: accession  collection_date  geo_loc_name
```

**b)** Join via Docker + Python stdlib (no extra installs)

```
docker run --rm -i -v "$PWD":/data -w /data nextstrain/base \
  python3 - <<'PY'
import csv
meta_path = "metadata_raw.tsv"
clade_path = "nextclade.tsv"
out_path  = "metadata_prepared.tsv"

# Map accession -> selected Nextclade fields (using first token of seqName)
clade_map = {}
with open(clade_path, newline='') as f:
    r = csv.DictReader(f, delimiter='\t')
    for row in r:
        acc = row['seqName'].split()[0]
        clade_map[acc] = {
            'clade': row.get('clade',''),
            'qc.overallStatus': row.get('qc.overallStatus',''),
            'totalMissing': row.get('totalMissing','')
        }

with open(out_path, 'w', newline='') as out, open(meta_path, newline='') as meta:
    w = csv.writer(out, delimiter='\t')
    w.writerow(['accession','collection_date','geo_loc_name','clade','qc.overallStatus','totalMissing'])
    for row in csv.reader(meta, delimiter='\t'):
        if not row: continue
        acc = row[0]
        extra = clade_map.get(acc, {'clade':'','qc.overallStatus':'','totalMissing':''})
        w.writerow(row + [extra['clade'], extra['qc.overallStatus'], extra['totalMissing']])
print("Wrote metadata_prepared.tsv")
PY
```

✅ **Checkpoint** `metadata_prepared.tsv` should have 6 columns including `clade` & QC.


* * * * *


### 1.2.4 Add `date`/`year`/`month` and ensure a `strain` column

Augur expects a `date` column (parsable) and uses **`strain`** (or `name`) to match metadata to tip names. We'll derive date fields and add `strain = accession`.

**a)** Derive date/year/month from collection_date

```
docker run --rm -i -v "$PWD":/data -w /data nextstrain/base \
  python3 - <<'PY'
import csv, re
from datetime import datetime
inp  = "metadata_prepared.tsv"
outp = "metadata_prepared_dates.tsv"

mon = {m.lower(): i for i,m in enumerate(
  ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"], start=1)}

def norm_date(s):
    if not s: return None, None, None
    s = s.strip()
    for fmt in ("%Y-%m-%d","%Y-%m","%Y"):
        try:
            dt = datetime.strptime(s, fmt)
            y = dt.year; m = dt.month if "%m" in fmt else 1; d = dt.day if "%d" in fmt else 1
            return f"{y:04d}-{m:02d}-{d:02d}", y, m
        except ValueError: pass
    m1 = re.match(r"^(\d{1,2})-([A-Za-z]{3})-(\d{4})$", s)
    if m1:
        d = int(m1.group(1)); mm = mon.get(m1.group(2).lower()); y = int(m1.group(3))
        if mm: return f"{y:04d}-{mm:02d}-{d:02d}", y, mm
    m2 = re.match(r"^([A-Za-z]{3})-(\d{4})$", s)
    if m2:
        mm = mon.get(m2.group(1).lower()); y = int(m2.group(2))
        if mm: return f"{y:04d}-{mm:02d}-01", y, mm
    m3 = re.search(r"(\d{4})", s)
    if m3:
        y = int(m3.group(1)); return f"{y:04d}-01-01", y, 1
    return None, None, None

with open(inp, newline='') as f, open(outp, "w", newline='') as g:
    r = csv.DictReader(f, delimiter="\t")
    fieldnames = r.fieldnames + ["date","year","month"]
    w = csv.DictWriter(g, delimiter="\t", fieldnames=fieldnames)
    w.writeheader()
    for row in r:
        iso, y, m = norm_date(row.get("collection_date",""))
        row["date"]  = iso or ""
        row["year"]  = y or ""
        row["month"] = m or ""
        w.writerow(row)
print(f"Wrote {outp}")
PY
```

**b)** Add 'strain' as the first column = accession (so Augur/Auspice can match tips)

```
awk 'BEGIN{FS=OFS="\t"} NR==1{print "strain",$0; next} {print $1,$0}' \
  metadata_prepared_dates.tsv > metadata_final.tsv
```


* * * * *


### 1.2.5. Normalise FASTA headers to **accession only**

This ensures tip names match `strain`.

```
awk 'BEGIN{OFS=""}
  /^>/ {h=$0; sub(/^>/,"",h); split(h,a," "); print ">",a[1]; next}
  {print}
' sa_h3n2_HA_2000_2025.fasta > sa_h3n2_HA_2000_2025.acc.fasta
```


### 1.2.6. (Option A) Use your **master reference** for alignment

If you are using a pre-chosen master reference (e.g. **[CY033009.1](www.ncbi.nlm.nih.gov/nuccore/CY033009.1)**):

```
# Fetch master reference FASTA from NCBI (once)
efetch -db nucleotide -id CY033009.1 -format fasta > reference_h3n2.fasta
```

* * * * *


### 1.2.7. Subsample with Augur, align to reference, build tree

> We use `nextstrain/base` image. (It may not support `--seed`; that’s OK.)

```
# Index (speeds up filtering)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur index \
    --sequences sa_h3n2_HA_2000_2025.acc.fasta \
    --output raw.idx
```

```
# Rule-based subsampling (tune group-by & counts)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur filter \
    --metadata metadata_final.tsv \
    --sequences sa_h3n2_HA_2000_2025.acc.fasta \
    --sequence-index raw.idx \
    --metadata-id-columns strain \
    --group-by clade year \
    --sequences-per-group 10 \
    --output-sequences curated.fasta \
    --output-metadata curated.tsv
```

```
# Align to master reference (constrained alignment)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur align \
    --sequences curated.fasta \
    --reference-sequence reference_h3n2.fasta \
    --output aligned.fasta \
    --fill-gaps
```

```
# ML tree + refine (time tree)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur tree \
    --alignment aligned.fasta \
    --output tree_raw.nwk \
    --nthreads 2

docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur refine \
    --tree tree_raw.nwk \
    --alignment aligned.fasta \
    --metadata curated.tsv \
    --output-tree tree.nwk \
    --timetree
```

✅ **Checkpoint** You should see `tree.nwk` in your directory.


* * * * *

### 1.2.8. Export for Auspice & view (be explicit about fields + host binding)

Older Augur exports may not auto-expose color fields. Specify them explicitly.

```
mkdir -p auspice

docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur export v2 \
    --tree tree.nwk \
    --metadata curated.tsv \
    --metadata-fields clade date year month geo_loc_name \
    --output auspice/sa-h3n2-2000-2025.json
```

Serve with host binding so all systems behave:

```
docker run -it --rm \
  -v "$PWD":/data -w /data \
  -p 4010:4000 \
  nextstrain/base \
  nextstrain view --host 0.0.0.0 auspice/
# open http://localhost:4010/sa-h3n2-2000-2025
```

You should now be able to **Color by**: `clade`, `year`, `month`, `geo_loc_name`, etc.


* * * * *

### 1.2.9. (Option B) Skip `augur align` by using Nextclade's aligned output

If you prefer fewer steps, you can have Nextclade write an aligned FASTA and reuse it:

```
docker run --rm -it \\
  -v "$PWD":/data \\
  -v "$HOME/.nextclade":/root/.nextclade \\
  nextstrain/nextclade:latest \\
  nextclade run \\
    --input-dataset /root/.nextclade/datasets/h3n2_ha \\
    --output-tsv /data/nextclade.tsv \\
    --output-fasta /data/nextclade_aligned.fasta \\
    /data/sa_h3n2_HA_2000_2025.acc.fasta

# Then skip 'augur align' and continue from 'augur tree' using nextclade_aligned.fasta
```

* * * * *

## Quick Troubleshooting (FAQs)

-   **No color options in Auspice** → Tip names and `strain` must match *exactly*. Ensure you used the **.acc.fasta** and that `metadata_final.tsv`'s first column is `strain` with the same values.

-   **"date/year/month" warnings** → Make sure you ran the date-deriving step and used `metadata_final.tsv`.

-   **Export complains about missing `strain`** → Use `metadata_final.tsv` (it adds `strain`), or add `strain` as the first column yourself.

-   **Viewer connection resets** → Use `--host 0.0.0.0` and map a port (e.g., `-p 4010:4000`). Try a different port if needed.

* * * * *

### Optional: newer Augur image for strict reproducibility

If you want the `--seed` option and latest flags, you can swap `nextstrain/base` for:

```
nextstrain/cli:latest
```

(e.g., `docker run -it --rm -v "$PWD":/data -w /data nextstrain/cli:latest augur filter ...`)


* * * * *
