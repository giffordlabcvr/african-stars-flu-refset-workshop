## 1.3 (Optional): Command-line approach with data downloaded from **GISAID** (web)

### Download from GISAID (recommended filters)

1.  Open GISAID's **EpiFlu** interface.

2.  Use the **Query Builder** (example):

    -   Virus/Subtype: **A/H3N2**
    -   Location: **South Africa**
    -   Collection date: **2018--2025**
    -   (Add any other constraints you need for your class/demo.)

3.  **Export sequences** as **FASTA**

    -   **Header template:** ensure the **first token is the GISAID ID** (`EPI_ISL_...`).
    -   It's fine to include extra fields after that, separated by `|`.
    -   Save as **`gisaid_ha.fasta`** in your working directory.

4.  **Export metadata** as **TSV/CSV**

    -   Choose **tab-delimited (TSV)**.
    -   Make sure the table includes at least: `Isolate_Id`, `Location`, `Collection_Date`, and (if available) `Clade`, `Host`, `Isolate_Name`.
    -   Save as **`gisaid_meta.tsv`**.

> Tip: Don't overthink column selection---our cleaning step later safely parses TSV and derives the fields Augur/Auspice need.

* * * * *

Quick pre-flight checks (on your downloads)
-------------------------------------------

Run these from your working directory (macOS/Linux):

### 1) Count sequences

`grep -c '^>' gisaid_ha.fasta`

### 2) Spot-check a few headers – the first token should be EPI_ISL_...

`grep '^>' gisaid_ha.fasta | head -5`

### 3) Confirm a '|' is present (not strictly required, but common)

`grep '^>' gisaid_ha.fasta | grep -c '|'`


## Next Steps

In the next steps we will:

1.  **Normalize** FASTA headers to the **left of the first `|`** and **de-duplicate** IDs;
2.  Run **Nextclade** (Docker) for QC + clades;
3.  Clean/merge **metadata**, then **downsample, align, and tree** with **Augur**;
4.  Export to **Auspice**;

Each step includes a brief explanation and a **checkpoint** so students can verify they're on track.

* * * * *

### 1.3.0. (One-time) Pull required images

```
docker pull nextstrain/nextclade:latest
docker pull nextstrain/base
```

* * * * *

### 1.3.1.  Normalize FASTA headers 

Keep only the **ID** (left of the first `|`), then drop any duplicate IDs (keep first).


```
# Normalize headers to the token before the first '|'
awk 'BEGIN{OFS=""}
  /^>/ { h=$0; sub(/^>/,"",h); split(h,a,"|"); id=a[1]; sub(/[[:space:]]+$/,"",id); print ">", id; next }
  { print }
' gisaid_ha.fasta > gisaid_ha.acc.fasta

# De-duplicate by normalized ID
awk '/^>/{k=$0; keep=!seen[k]++} { if(keep) print }' \
  gisaid_ha.acc.fasta > gisaid_ha.acc.uniq.fasta
```

✅ **Checkpoint (should print nothing):**

```
grep '^>' gisaid_ha.acc.uniq.fasta | sort | uniq -d | sed -n '1,10p'
```

* * * * *

### 1.3.2. Nextclade QC + clades

Get the H3N2-HA dataset (cached under `~/.nextclade`)

```
docker run --rm -it -v "$HOME/.nextclade":/root/.nextclade nextstrain/nextclade:latest \
  nextclade dataset get --name nextstrain/flu/h3n2/ha \
  --output-dir /root/.nextclade/datasets/h3n2_ha
```

2b. Run Nextclade

```
docker run --rm -it \
  -v "$PWD":/data \
  -v "$HOME/.nextclade":/root/.nextclade \
  nextstrain/nextclade:latest \
  nextclade run \
    --input-dataset /root/.nextclade/datasets/h3n2_ha \
    --output-tsv /data/nextclade.tsv \
    /data/gisaid_ha.acc.uniq.fasta
```

✅ **Checkpoint:** `nextclade.tsv` exists (try `head nextclade.tsv`).

* * * * *

### 1.3.3. Clean GISAID metadata

This trims to the fields Augur/Auspice need and derives `date/year/month` (safe TSV parsing; split `Location`; normalize dates).

```
docker run --rm -i -v "$PWD":/data -w /data nextstrain/base \
  python3 - <<'PY'
import csv, re
from datetime import datetime

inp  = "gisaid_meta.tsv"
outp = "meta_clean.tsv"

def split_loc(s):
    parts = [p.strip() for p in (s or "").split('/') if p.strip()]
    parts += [""] * (4 - len(parts))
    return parts[:4]  # region, country, division, location

def norm_date(s):
    if not s: return ("","","")
    s = s.strip()
    for fmt in ("%Y-%m-%d","%Y-%m","%Y"):
        try:
            dt = datetime.strptime(s, fmt)
            y = dt.year; m = dt.month if "%m" in fmt else 1
            return (dt.strftime("%Y-%m-%d") if "%d" in fmt else f"{y:04d}-{m:02d}-01",
                    str(y), f"{m:02d}")
        except ValueError: pass
    m = re.search(r"(\d{4})", s)
    if m: return (f"{m.group(1)}-01-01", m.group(1), "01")
    return ("","","")

with open(inp, newline='') as f, open(outp, "w", newline='') as g:
    r = csv.DictReader(f, delimiter="\t")
    cols_out = ["Isolate_Id","Isolate_Name","Subtype","Clade","Host",
                "region","country","division","location","Collection_Date",
                "date","year","month"]
    w = csv.DictWriter(g, delimiter="\t", fieldnames=cols_out); w.writeheader()
    for row in r:
        reg, ctry, div, loc = split_loc(row.get("Location",""))
        d, y, m = norm_date(row.get("Collection_Date",""))
        w.writerow({
          "Isolate_Id": row.get("Isolate_Id",""),
          "Isolate_Name": row.get("Isolate_Name",""),
          "Subtype": row.get("Subtype",""),
          "Clade": row.get("Clade",""),
          "Host": row.get("Host",""),
          "region": reg, "country": ctry, "division": div, "location": loc,
          "Collection_Date": row.get("Collection_Date",""),
          "date": d, "year": y, "month": m
        })
print(f"Wrote {outp}")
PY
```

✅ **Checkpoint:** `meta_clean.tsv` exists.\
(Optional sanity check counts:)

```
echo "FASTA seqs:" $(grep -c '^>' gisaid_ha.acc.uniq.fasta)
echo "metadata rows:" $(tail -n +2 meta_clean.tsv | wc -l)
```

### 1.3.4 Merge metadata + Nextclade (keyed by `Isolate_Id`)

We map `nextclade.tsv` to `Isolate_Id` (the **same IDs** you put in FASTA headers).

```
docker run --rm -i -v "$PWD":/data -w /data nextstrain/base \
  python3 - <<'PY'
import csv

meta_in  = "meta_clean.tsv"
clade_in = "nextclade.tsv"
outp     = "metadata_final.tsv"
missed_log = "nextclade_unmatched_ids.txt"

clade_map = {}
with open(clade_in, newline='') as f:
    r = csv.DictReader(f, delimiter="\t")
    for row in r:
        acc = row['seqName'].split('|')[0]  # safe even if no '|'
        clade_map[acc] = {
          'nextclade_clade': row.get('clade',''),
          'qc.overallStatus': row.get('qc.overallStatus','')
        }

missed = set()
with open(meta_in, newline='') as f, open(outp, "w", newline='') as g:
    r = csv.DictReader(f, delimiter="\t")
    cols_out = ["strain","Isolate_Id","Isolate_Name","Subtype","Clade","nextclade_clade",
                "Host","region","country","division","location","Collection_Date",
                "date","year","month","qc.overallStatus"]
    w = csv.DictWriter(g, delimiter="\t", fieldnames=cols_out); w.writeheader()
    for row in r:
        iso = row["Isolate_Id"]
        nc  = clade_map.get(iso)
        if not nc: missed.add(iso); nc = {'nextclade_clade':'','qc.overallStatus':''}
        w.writerow({
          "strain": iso, "Isolate_Id": iso,
          "Isolate_Name": row["Isolate_Name"], "Subtype": row["Subtype"],
          "Clade": row["Clade"], "nextclade_clade": nc['nextclade_clade'],
          "Host": row["Host"], "region": row["region"], "country": row["country"],
          "division": row["division"], "location": row["location"],
          "Collection_Date": row["Collection_Date"], "date": row["date"],
          "year": row["year"], "month": row["month"],
          "qc.overallStatus": nc["qc.overallStatus"]
        })

with open(missed_log,"w") as h:
    for m in sorted(missed): h.write(m+"\n")

print(f"Wrote {outp}. Unmatched in Nextclade: {len(missed)} (see {missed_log})")
PY
```

✅ **Checkpoint:** `metadata_final.tsv` exists.\
(optional) `wc -l nextclade_unmatched_ids.txt` should be **0** (or small).

* * * * *

### 1.3.5 Augur: downsample, align, tree, refine

We'll keep **≤10 sequences per clade per year** (tune as needed

```
# index
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur index \
    --sequences gisaid_ha.acc.uniq.fasta \
    --output raw.idx

# filter (downsample)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur filter \
    --metadata metadata_final.tsv \
    --sequences gisaid_ha.acc.uniq.fasta \
    --sequence-index raw.idx \
    --metadata-id-columns strain \
    --group-by nextclade_clade year \
    --sequences-per-group 10 \
    --output-sequences curated.fasta \
    --output-metadata curated.tsv

# align (or use Nextclade-aligned if you prefer)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur align \
    --sequences curated.fasta \
    --output aligned.fasta \
    --fill-gaps

# tree
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur tree \
    --alignment aligned.fasta \
    --output tree_raw.nwk \
    --nthreads 2

# refine (time-scale + metadata)
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur refine \
    --tree tree_raw.nwk \
    --alignment aligned.fasta \
    --metadata curated.tsv \
    --output-tree tree.nwk \
    --timetree
```

✅ **Checkpoint:** `curated.fasta`, `aligned.fasta`, `tree.nwk` exist.\
(optional)

```
echo "Curated seqs:" $(grep -c '^>' curated.fasta)
```

### 1.3.6 Export to Auspice & view

```
mkdir -p auspice

docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur export v2 \
    --tree tree.nwk \
    --metadata curated.tsv \
    --metadata-fields nextclade_clade Clade date year month region country division location Host \
    --output auspice/gisaid-h3n2-ha.json

docker run -it --rm \
  -v "$PWD":/data -w /data \
  -p 4010:4000 \
  nextstrain/base \
  nextstrain view --host 0.0.0.0 auspice/
```

Open: `http://localhost:4010/gisaid-h3n2-ha`\
✅ **Checkpoint:** In Auspice, try **Color by**: `nextclade_clade`, `year`, `country`.


### 1.3.7 (Optional) Add **your own sequences** to the tree

### 7a. Prepare your files

-   `myseqs.fasta` (headers like `>MYSEQ_001`, `>MYSEQ_002`, ...)

-   `my_meta.tsv` (same columns as `metadata_final.tsv`; **must** have `strain` = FASTA header)

Minimal template (copy to `my_meta.tsv` and edit):

```
strain	Isolate_Id	Isolate_Name	Subtype	Clade	nextclade_clade	Host	region	country	division	location	Collection_Date	date	year	month	qc.overallStatus
MYSEQ_001	MYSEQ_001	A/South_Africa/Seq1/2023	H3N2		Human	Africa	South Africa	Western Cape	Cape Town	2023-05-15	2023-05-15	2023	05	pass
MYSEQ_002	MYSEQ_002	A/South_Africa/Seq2/2024	H3N2		Human	Africa	South Africa	Gauteng	Johannesburg	2024-02-01	2024-02-01	2024	02	pass
```

> Better: run Nextclade on `myseqs.fasta` too and fill `nextclade_clade`/`qc.overallStatus` from its TSV, but it's optional for the demo.

### 7b. Combine with GISAID

```
# Combine FASTA
cat gisaid_ha.acc.uniq.fasta myseqs.fasta > combined.fasta

# Combine metadata (header from GISAID metadata_final.tsv)
(head -n 1 metadata_final.tsv && tail -n +2 metadata_final.tsv && tail -n +2 my_meta.tsv) \
  > combined_meta.tsv
```

### 7c. Re-run Augur on the combined set

```
docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur index --sequences combined.fasta --output raw.idx

docker run -it --rm -v "$PWD":/data -w /data nextstrain/base \
  augur filter \
    --metadata combined_meta.tsv \
    --sequences combined.fasta \
    --sequence-index raw.idx \
    --metadata-id-columns strain \
    --group-by nextclade_clade year \
    --sequences-per-group 10 \
    --output-sequences curated.fasta \
    --output-metadata curated.tsv

# (align, tree, refine, export, view) — same as Steps 5–6
```

✅ **Checkpoint:** your `MYSEQ_*` tips appear in Auspice alongside GISAID references.


* * * * *
